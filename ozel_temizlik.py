import re

# 1.1. Negasyon (Olumsuzluk) Listesi
# En sÄ±k kullanÄ±lan olumsuzluk kelimeleri ve ekleri
NEGATORS = ['deyil', 'yox', 'yoxdur', 'deÄŸil', 'olmasÄ±n', 'bilmirÉ™m', 'É™sla', 'heÃ§'] 

# 1.2. Emoji HaritasÄ± (Duyguya gÃ¶re basitleÅŸtirilmiÅŸ)
# Emojilerin anlamlÄ± metin karÅŸÄ±lÄ±klarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi
EMOJI_MAP = {
    'ğŸ˜Š': ' EMO_POS ', 'ğŸ˜€': ' EMO_POS ', 'ğŸ˜ƒ': ' EMO_POS ', 'ğŸ˜‚': ' EMO_POS ',
    'ğŸ˜': ' EMO_LOVE ', 'ğŸ˜˜': ' EMO_LOVE ', 'ğŸ¥°': ' EMO_LOVE ',
    'ğŸ™': ' EMO_NEG ', 'ğŸ˜¥': ' EMO_NEG ', 'ğŸ˜': ' EMO_NEG ', 'ğŸ˜­': ' EMO_NEG ',
    'ğŸ˜¡': ' EMO_NEG ', 'ğŸ˜ ': ' EMO_NEG ', 'ğŸ‘': ' EMO_NEG ',
    'ğŸ¤”': ' EMO_NEU ', 'ğŸ¤·â€â™€ï¸': ' EMO_NEU ', 'ğŸ¤¦â€â™€ï¸': ' EMO_NEU ' 
    # Not: GerÃ§ek projede bu liste Ã§ok daha geniÅŸ olmalÄ±dÄ±r.
}

# 1.4. Deasciify (Slang DÃ¼zeltme) HaritasÄ±
# Azerbaycanca sosyal medya hatalarÄ± iÃ§in (Ã§ox, yaxÅŸÄ± gibi karakterler)
SLANG_MAP = {
    r'\bcox\b': 'Ã§ox', 
    r'\byaxsi\b': 'yaxÅŸÄ±', 
    r'\bcunki\b': 'Ã§Ã¼nki',
    r'\bele\b': 'belÉ™',
    r'\bgulle\b': 'gÃ¼llÉ™',
    r'\bolkeler\b': 'Ã¶lkÉ™lÉ™r',
    r'\boz\b': 'Ã¶z'
}

def handle_negation(text):
    """Olumsuzluk kelimesinden (deyil, yox vb.) sonraki 3 kelimeyi _NEG etiketiyle iÅŸaretler."""
    tokens = text.split()
    new_tokens = []
    negate_until = -1 # Olumsuzlama etkisinin biteceÄŸi kelime indeksi

    for i, token in enumerate(tokens):
        # 1. Olumsuzluk kelimesi mi?
        if token in NEGATORS:
            new_tokens.append(token)
            # Etiketlemeyi kendisinden sonraki 3 kelime iÃ§in yap
            negate_until = i + 3
        # 2. Olumsuzluk etkisi devam ediyor mu?
        elif i < negate_until:
            # Token eÄŸer bir etiket deÄŸilse (Ã¶rn. <PRICE> veya EMO_POS) etiketle
            if not re.match(r'<.*?>|EMO_.*?', token):
                 new_tokens.append(token + "_NEG")
            else:
                 new_tokens.append(token) # Etiketleri bozmamak iÃ§in
        # 3. Normal kelime
        else:
            new_tokens.append(token)

    return " ".join(new_tokens)

def map_emojis_and_normalize(text):
    """Metindeki emojileri EMOJI_MAP'e gÃ¶re metin etiketlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    for emo, replacement in EMOJI_MAP.items():
        text = text.replace(emo, replacement)
    return text

def split_hashtags(text):
    """Hashtag'lerdeki CamelCase yapÄ±sÄ±nÄ± ayÄ±rÄ±r (#QarabagIsBack -> Qarabag Is Back)."""
    
    # 1. # iÅŸaretini kaldÄ±r
    text = re.sub(r'#', '', text) 
    
    # 2. Bir kÃ¼Ã§Ã¼k harf, ardÄ±ndan bir bÃ¼yÃ¼k harf gelirse araya boÅŸluk ekle
    # Ã–rneÄŸin: 'GozelAzerbaycan' -> 'Gozel Azerbaycan'
    text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)
    
    # Not: KiÅŸi 1 bu Ã§Ä±ktÄ±yÄ± lower_az'a beslemelidir.
    return text

def deasciify_slang(text):
    """YaygÄ±n Azerbaycan sosyal medya kÄ±saltmalarÄ±nÄ±/hatalarÄ±nÄ± dÃ¼zeltir (Deasciify)."""
    for pattern, replacement in SLANG_MAP.items():
        # \b tam kelime sÄ±nÄ±rÄ±nÄ± kontrol eder (Ã¶rn: 'boxca' kelimesini etkilemeden 'cox' kelimesini deÄŸiÅŸtirir)
        text = re.sub(pattern, replacement, text)
    return text

def detect_domain(text):
    """Metnin tÃ¼rÃ¼nÃ¼ (news, social, reviews, general) kural tabanlÄ± tespit eder."""
    text_lower = text.lower()
    
    # Kural 1: Social Media (Ã‡ok sayÄ±da hashtag, kullanÄ±cÄ± adÄ±, slang)
    if text_lower.count('#') > 1 or text_lower.count('@') > 1 or 'hÉ™hÉ™hÉ™' in text_lower or 'lol' in text_lower:
        return 'social'
    
    # Kural 2: Reviews (Fiyat, puan, hizmet/Ã¼rÃ¼n kelimeleri)
    elif any(keyword in text_lower for keyword in ['fiyat', 'qiymÉ™t', 'ulduz', 'star', 'hizmet', 'xidmÉ™t', 'kargo', 'teslimat']):
        return 'reviews'
        
    # Kural 3: News (Resmiyet belirten kelimeler)
    elif any(keyword in text_lower for keyword in ['rÉ™smi', 'aÃ§Ä±qlama', 'baÅŸkan', 'nazir', 'Ã¶lkÉ™', 'parlament']):
        return 'news'
    
    # DiÄŸerleri
    else:
        return 'general'

def add_domain_tag(text, domain):
    """Corpus iÃ§in metnin baÅŸÄ±na domain etiketini ekler (Ã–rn: DOM_NEWS Bu haber...)."""
    return f"DOM_{domain.upper()} {text}"

def domain_specific_normalize(text, domain):
    """Sadece Reviews domain'i iÃ§in fiyat ve yÄ±ldÄ±z/puanlarÄ± etiketler."""
    if domain == 'reviews':
        # 1. Fiyat etiketleme (Ã–rn: 100 manat, 50TL, 25$) -> <PRICE>
        # (SayÄ±lar, ardÄ±ndan boÅŸluklar ve para birimleri)
        text = re.sub(r'\d+[\s\.]*(manat|azn|tl|usd|\$|â‚¬)', '<PRICE>', text, flags=re.IGNORECASE)
        
        # 2. YÃ¼ksek Puan Etiketleme (4, 5, MÃ¼kemmel) -> <STARS_HIGH>
        # 5/5, 4/5, 5 ulduz, 4 yÄ±ldÄ±z vb.
        text = re.sub(r'([4-5]\s*/\s*5)|([4-5]\s*ulduz)|([4-5]\s*yÄ±ldÄ±z)|mÃ¼kÉ™mmÉ™l|É™la', '<STARS_HIGH>', text, flags=re.IGNORECASE)
        
        # 3. DÃ¼ÅŸÃ¼k Puan Etiketleme (1, 2) -> <STARS_LOW>
        # 1/5, 2/5, 1 ulduz, 2 yÄ±ldÄ±z vb.
        text = re.sub(r'([1-2]\s*/\s*5)|([1-2]\s*ulduz)|([1-2]\s*yÄ±ldÄ±z)|kÃ¶tÃ¼|pis', '<STARS_LOW>', text, flags=re.IGNORECASE)

    return text